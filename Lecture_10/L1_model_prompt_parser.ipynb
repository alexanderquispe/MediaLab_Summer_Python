{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4da14a7",
   "metadata": {},
   "source": [
    "# Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7579bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5326aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee4dc8",
   "metadata": {},
   "source": [
    "* gpt-4-1106-preview\n",
    "* gpt-4-vision-preview\n",
    "* gpt-4\n",
    "* gpt-4-32k\n",
    "* gpt-4-0613\n",
    "* gpt-4-32k-0613\n",
    "\n",
    "* gpt-3.5-turbo-1106\n",
    "* gpt-3.5-turbo\n",
    "* gpt-3.5-turbo-16k\n",
    "* gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174178c",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30a5eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo-1106\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "328404cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9bfe8910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12150552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please rewrite the following text into a more formal \n",
      "and professional journalistic inquiry Formal, objective journalism style with a focus on clarity and accuracy.\n",
      "text: ```\n",
      "Dear Mayor's Office,\n",
      "\n",
      "I am writing an article for the local newspaper on the recent policy changes regarding public transportation. I would appreciate it if you could provide me with detailed information about these changes, including the reasons behind them and the expected impact on daily commuters.\n",
      "\n",
      "I am also interested in any statistics or data you might have on public transport usage in our city, as well as any future plans for improvements or expansions. This information will be crucial for a comprehensive and balanced article.\n",
      "\n",
      "Thank you for your time and assistance.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casual_journalist_inquiry = \"\"\"\n",
    "Hey there,\n",
    "\n",
    "I'm working on a piece for our local paper about the new changes to the \n",
    "bus and train services in town. Could you send over some details about what's \n",
    "changed and why? It would be really helpful to understand what's going on, \n",
    "especially for people who use the bus or train every day.\n",
    "\n",
    "Also, if you have any numbers on how many people take the bus or train, that'd be \n",
    "great. And any future plans for the services? That info would really round out my article.\n",
    "\n",
    "Thanks a bunch,\n",
    "[Your Name]\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"Formal, objective journalism style with a focus on clarity and accuracy\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Please rewrite the following text into a more formal \n",
    "and professional journalistic inquiry {style}.\n",
    "text: ```{journalist_inquiry}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69a3560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Mayor's Office,\\n\\nI am currently conducting research for an article to be published in the local newspaper regarding the recent policy changes pertaining to public transportation. I kindly request detailed information regarding the rationale behind these changes and their anticipated effects on daily commuters.\\n\\nAdditionally, I am seeking any available statistics or data related to public transport usage within our city, as well as any forthcoming plans for enhancements or expansions. This information is essential for the development of a comprehensive and impartial article.\\n\\nThank you for your attention and cooperation.\\n\\nSincerely,\\n[Your Name]\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703998b",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d774919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/e8/67/17a732ee99a7a383b5fd51ca671030e9f9d22e6e85af8873d20e2e01f7fd/langchain-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/ae/53/8c006de775834cd4ea64a445402dc195caeebb77dc76b7defb9b3887cb0d/dataclasses_json-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.13 (from langchain)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.13 from https://files.pythonhosted.org/packages/2a/24/224115d2666ff3ff4917f2ebc98b9da2d2fe8835ec57909ceca5972a117e/langchain_community-0.0.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.9 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.9 from https://files.pythonhosted.org/packages/f1/40/5472987308a9c8611c200a0455dd1e93a1e95d5dfb9c6e06f6ff63917512/langchain_core-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.13-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.77 from https://files.pythonhosted.org/packages/a1/3f/0808382e9d0b504e727dbaf86f1fcbe59472cac17a205644a5f78b11c36b/langsmith-0.0.83-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.83-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\anaconda\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\anaconda\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\anaconda\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/57/e9/4368d49d3b462da16a3bac976487764a84dd85cef97232c7bd61f5bdedf3/marshmallow-3.20.2-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\anaconda\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.9->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\anaconda\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\anaconda\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.1-py3-none-any.whl (802 kB)\n",
      "   ---------------------------------------- 0.0/802.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 92.2/802.4 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 225.3/802.4 kB 2.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 358.4/802.4 kB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 481.3/802.4 kB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 501.8/802.4 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 501.8/802.4 kB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 645.1/802.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/802.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/802.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/802.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 802.4/802.4 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.13-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.6 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.13-py3-none-any.whl (228 kB)\n",
      "   ---------------------------------------- 0.0/228.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/228.7 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 153.6/228.7 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/228.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/228.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/228.7 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/228.7 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 228.7/228.7 kB 735.5 kB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 41.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 248.8 kB/s eta 0:00:00\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 834.2 kB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   -------------------------------------- - 51.2/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 910.0 kB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 langchain-0.1.1 langchain-community-0.0.13 langchain-core-0.1.13 langsmith-0.0.83 marshmallow-3.20.2 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4634e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec3d0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3a8fcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0301', temperature=0.0, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826afa0",
   "metadata": {},
   "source": [
    "### Prompt template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a0cbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9960491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5320102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1be455ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b958c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c378be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Hey,\n",
    "\n",
    "I'm really frustrated with the programming class I signed up for. \n",
    "The lessons are super confusing, and the instructor just zips through\n",
    "the topics without making sure everyone's on the same page. It's like \n",
    "trying to catch a train that's already left the station!\n",
    "\n",
    "And don't get me started on the homework assignments. They're nothing \n",
    "like what we cover in class, and the online resources are about as helpful\n",
    "as a screen door on a submarine. I'm at my wit's end here.\n",
    "\n",
    "Can you guys do something about this? Maybe slow down the pace, or provide \n",
    "some extra help or resources? Anything would be a big help at this point.\n",
    "\n",
    "Thanks,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4201df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56260980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45fbfc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello,\n",
      "\n",
      "I would like to express my frustration with the programming class I am currently enrolled in. The lessons are quite confusing, and the instructor moves through the material quickly without ensuring that everyone understands. It feels like trying to catch a train that has already left the station.\n",
      "\n",
      "Furthermore, the homework assignments are not aligned with what we cover in class, and the online resources are not very helpful. I am feeling overwhelmed and unsure of how to proceed.\n",
      "\n",
      "Would it be possible to slow down the pace of the class or provide additional resources or support? Any assistance would be greatly appreciated.\n",
      "\n",
      "Thank you.\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "925fad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Recipient],\n",
      "\n",
      "We received your message regarding the programming class and would like to thank you for your interest. We would like to kindly remind you that using polite language is essential in all forms of communication. A simple 'please' or 'thank you' not only demonstrates good manners, but also shows that you are serious and respectful. This is similar to coding, where attention to detail is crucial.\n",
      "\n",
      "Furthermore, we would like to emphasize that learning to code requires dedication and effort beyond attending classes. It is comparable to learning to play the guitar, where practice is essential to master the chords. Therefore, we encourage you to put in the necessary hours outside of class to improve your skills.\n",
      "\n",
      "We are here to support you in your learning journey, but it is also important for you to take responsibility and remember the importance of practice. We wish you all the best and look forward to seeing your progress.\n",
      "\n",
      "Sincerely,\n",
      "[Your Service Team]\n"
     ]
    }
   ],
   "source": [
    "service_reply = \"\"\"Hey,\n",
    "\n",
    "Got your message about the programming class. First off, \n",
    "gotta say, manners go a long way. A simple 'please' or 'thank you' \n",
    "isn't just about being polite, it's about showing you're serious and respectful.\n",
    "It's kinda like coding – the small details matter.\n",
    "\n",
    "And hey, speaking of coding, it's not something you can learn just by \n",
    "showing up to class and zoning out. It's like trying to learn guitar \n",
    "without ever practicing your chords. You gotta put in the hours outside \n",
    "of class too, you know? Practice makes perfect and all that jazz.\n",
    "\n",
    "So, while we’re totally here to help you out, it's also a bit on you to \n",
    "put in the work and remember those magic words. Keep at it, and don't forget, \n",
    "practice, practice, practice!\n",
    "\n",
    "Catch ya later,\n",
    "[Your Service Team]\n",
    "\"\"\"\n",
    "\n",
    "service_style_harvard = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in HARVARD format\\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_harvard,\n",
    "    text=service_reply)\n",
    "\n",
    "#print(service_messages[0].content)\n",
    "\n",
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac820ffa",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66a45bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f281f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"regalo\": true,\n",
      "    \"días_entrega\": 3,\n",
      "    \"valor_precio\": [\"Me costó un poco más de lo que suelo gastar en regalos\", \"definitivamente valió la pena\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "customer_review_spanish = \"\"\"\\\n",
    "Estoy encantado con la compra del nuevo robot de cocina para mi madre en \n",
    "el día de la madre. Es el modelo más reciente y cuenta con múltiples funciones: \n",
    "puede picar, batir, amasar y hasta cocinar al vapor. Lo pedí a última hora, \n",
    "pero afortunadamente llegó en solo tres días. A mi madre le encanta cocinar, \n",
    "y aunque al principio estaba reticente a la tecnología, ahora está fascinada\n",
    "con todas las posibilidades que ofrece. Me costó un poco más de lo que suelo\n",
    "gastar en regalos, pero viendo la sonrisa en el rostro de mi madre, definitivamente\n",
    "valió la pena.\n",
    "\"\"\"\n",
    "\n",
    "review_template_spanish = \"\"\"\\\n",
    "Para el siguiente texto, extrae la siguiente información:\n",
    "\n",
    "regalo: ¿Fue el artículo comprado como un regalo para alguien más? \n",
    "Responde Verdadero si sí, Falso si no o desconocido.\n",
    "\n",
    "días_entrega: ¿Cuántos días tardó en llegar el producto? \n",
    "Si esta información no se encuentra, escribe -1.\n",
    "\n",
    "valor_precio: Extrae cualquier frase sobre el valor o precio \n",
    "y preséntalas en una lista separada por comas en Python.\n",
    "\n",
    "Formatea la salida como JSON con las siguientes claves:\n",
    "regalo\n",
    "días_entrega\n",
    "valor_precio\n",
    "\n",
    "texto: {text}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template_spanish)\n",
    "messages = prompt_template.format_messages(text=customer_review_spanish)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b04dd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9af15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c44cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
